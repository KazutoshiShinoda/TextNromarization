{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec(window=1, min_count=2)\n",
    "\n",
    "sentences = [[\"a\",\"b\",\"c\",\"a\",\"b\",\"a\",\"b\",\"b\"],[\"a\",\"a\",\"a\"]]\n",
    "model.build_vocab(sentences, keep_raw_vocab=True)\n",
    "sentences = [[\"d\",\"d\",\"d\"]*10,[\"d\",\"a\",\"a\"]*10+[\"c\"]]\n",
    "model.build_vocab(sentences, keep_raw_vocab=True, update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': <gensim.models.keyedvectors.Vocab at 0x7ff737851b70>,\n",
       " 'b': <gensim.models.keyedvectors.Vocab at 0x7ff7378512e8>,\n",
       " 'd': <gensim.models.keyedvectors.Vocab at 0x7ff737851a20>}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec(window=1, min_count=2)\n",
    "\n",
    "sentences = [[\"a\",\"b\",\"c\",\"a\",\"b\",\"a\",\"b\",\"b\"],[\"a\",\"a\",\"a\"]]\n",
    "model.build_vocab(sentences, keep_raw_vocab=True)\n",
    "model.train(sentences, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': <gensim.models.keyedvectors.Vocab at 0x7ff7378515c0>,\n",
       " 'b': <gensim.models.keyedvectors.Vocab at 0x7ff737845f28>}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'a': 40, 'b': 10, 'c': 10})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.raw_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00088881073"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"a\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [[\"d\",\"d\",\"d\"]*10,[\"d\",\"a\",\"a\"]*10+[\"c\"]]\n",
    "model.build_vocab(sentences, keep_raw_vocab=True, update=True)\n",
    "model.train(sentences, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00081965426"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"a\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0037984129"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"d\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': <gensim.models.keyedvectors.Vocab at 0x7ff7378515c0>,\n",
       " 'b': <gensim.models.keyedvectors.Vocab at 0x7ff737845f28>,\n",
       " 'd': <gensim.models.keyedvectors.Vocab at 0x7ff737851128>}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'a': 20, 'd': 40})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.raw_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_word2vec.Word2Vec(size=128, window=5, min_count=1, keep_raw_vocab=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 3 1\n",
      "a 3\n",
      "c 3 1\n",
      "c 3\n",
      "a {'a': <gensim.models.keyedvectors.Vocab object at 0x7f2341b0f198>, 'c': <gensim.models.keyedvectors.Vocab object at 0x7f22784b41d0>} False\n",
      "2 defaultdict(<class 'int'>, {'a': 3, 'c': 3})\n",
      "4 defaultdict(<class 'int'>, {'a': 3, 'c': 3})\n",
      "6 defaultdict(<class 'int'>, {'a': 3, 'c': 3})\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab([[\"c\",\"c\",\"c\",\"a\"],[\"a\"],[\"a\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0010310465"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"a\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 defaultdict(<class 'int'>, {'b': 1, 'a': 4, 'c': 4})\n",
      "7 defaultdict(<class 'int'>, {'b': 1, 'a': 4, 'c': 4})\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab([[\"b\",\"a\",\"c\"]], update=True, n_build=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0010310465"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"a\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0017000992"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"b\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train([[\"a\", \"c\"]*100,[\"a\"]*100,[\"c\"]*100], total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0073690359"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"a\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train([[\"a\", \"b\"]*100,[\"b\"]*100,[\"c\"]*100], total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "INPUT_PATH = \"../../input/\"\n",
    "OUTPUT_PATH = \"../../output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['output_1.csv', 'output_6.csv', 'output_11.csv', 'output_16.csv',\n",
    "         'output_21.csv', 'output_91.csv', 'output_96.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 100000 sentences. Now in output_1.csv\n",
      "Trained 200000 sentences. Now in output_1.csv\n",
      "Trained 300000 sentences. Now in output_1.csv\n",
      "Trained 400000 sentences. Now in output_1.csv\n",
      "Trained 500000 sentences. Now in output_1.csv\n",
      "Trained 600000 sentences. Now in output_1.csv\n",
      "Trained 700000 sentences. Now in output_1.csv\n",
      "Trained 800000 sentences. Now in output_1.csv\n",
      "Trained 900000 sentences. Now in output_1.csv\n",
      "Trained 1000000 sentences. Now in output_1.csv\n",
      "Trained 1100000 sentences. Now in output_1.csv\n",
      "Trained 1200000 sentences. Now in output_1.csv\n",
      "Trained 1300000 sentences. Now in output_1.csv\n",
      "Trained 1400000 sentences. Now in output_1.csv\n",
      "Trained 1500000 sentences. Now in output_1.csv\n",
      "Trained 1600000 sentences. Now in output_1.csv\n",
      "Trained 1700000 sentences. Now in output_1.csv\n",
      "Trained 1800000 sentences. Now in output_1.csv\n",
      "Trained 1900000 sentences. Now in output_1.csv\n",
      "Trained 2000000 sentences. Now in output_1.csv\n",
      "Trained 2100000 sentences. Now in output_1.csv\n",
      "Trained 2200000 sentences. Now in output_1.csv\n",
      "Trained 2300000 sentences. Now in output_1.csv\n",
      "Trained 2400000 sentences. Now in output_1.csv\n",
      "Trained 2500000 sentences. Now in output_1.csv\n",
      "Trained 2600000 sentences. Now in output_1.csv\n",
      "Trained 2700000 sentences. Now in output_1.csv\n",
      "Trained 2800000 sentences. Now in output_1.csv\n",
      "Trained 2900000 sentences. Now in output_1.csv\n",
      "Trained 3000000 sentences. Now in output_1.csv\n",
      "Trained 3100000 sentences. Now in output_1.csv\n",
      "Trained 3200000 sentences. Now in output_1.csv\n",
      "Trained 3300000 sentences. Now in output_1.csv\n",
      "Trained 3400000 sentences. Now in output_1.csv\n",
      "Trained 3500000 sentences. Now in output_1.csv\n",
      "Trained 3600000 sentences. Now in output_1.csv\n",
      "Trained 3700000 sentences. Now in output_1.csv\n",
      "Trained 3800000 sentences. Now in output_1.csv\n",
      "Trained 3900000 sentences. Now in output_1.csv\n",
      "Trained 4000000 sentences. Now in output_1.csv\n",
      "Trained 4100000 sentences. Now in output_1.csv\n",
      "Trained 4200000 sentences. Now in output_1.csv\n",
      "Trained 4300000 sentences. Now in output_1.csv\n",
      "Trained 4400000 sentences. Now in output_1.csv\n",
      "Trained 4500000 sentences. Now in output_6.csv\n",
      "Trained 4600000 sentences. Now in output_6.csv\n",
      "Trained 4700000 sentences. Now in output_6.csv\n",
      "Trained 4800000 sentences. Now in output_6.csv\n",
      "Trained 4900000 sentences. Now in output_6.csv\n",
      "Trained 5000000 sentences. Now in output_6.csv\n",
      "Trained 5100000 sentences. Now in output_6.csv\n",
      "Trained 5200000 sentences. Now in output_6.csv\n",
      "Trained 5300000 sentences. Now in output_6.csv\n",
      "Trained 5400000 sentences. Now in output_6.csv\n",
      "Trained 5500000 sentences. Now in output_6.csv\n",
      "Trained 5600000 sentences. Now in output_6.csv\n",
      "Trained 5700000 sentences. Now in output_6.csv\n",
      "Trained 5800000 sentences. Now in output_6.csv\n",
      "Trained 5900000 sentences. Now in output_6.csv\n",
      "Trained 6000000 sentences. Now in output_6.csv\n",
      "Trained 6100000 sentences. Now in output_6.csv\n",
      "Trained 6200000 sentences. Now in output_6.csv\n",
      "Trained 6300000 sentences. Now in output_6.csv\n",
      "Trained 6400000 sentences. Now in output_6.csv\n",
      "Trained 6500000 sentences. Now in output_6.csv\n",
      "Trained 6600000 sentences. Now in output_6.csv\n",
      "Trained 6700000 sentences. Now in output_6.csv\n",
      "Trained 6800000 sentences. Now in output_6.csv\n",
      "Trained 6900000 sentences. Now in output_6.csv\n",
      "Trained 7000000 sentences. Now in output_6.csv\n",
      "Trained 7100000 sentences. Now in output_6.csv\n",
      "Trained 7200000 sentences. Now in output_6.csv\n",
      "Trained 7300000 sentences. Now in output_6.csv\n",
      "Trained 7400000 sentences. Now in output_6.csv\n",
      "Trained 7500000 sentences. Now in output_6.csv\n",
      "Trained 7600000 sentences. Now in output_6.csv\n",
      "Trained 7700000 sentences. Now in output_6.csv\n",
      "Trained 7800000 sentences. Now in output_6.csv\n",
      "Trained 7900000 sentences. Now in output_6.csv\n",
      "Trained 8000000 sentences. Now in output_6.csv\n",
      "Trained 8100000 sentences. Now in output_6.csv\n",
      "Trained 8200000 sentences. Now in output_6.csv\n",
      "Trained 8300000 sentences. Now in output_6.csv\n",
      "Trained 8400000 sentences. Now in output_6.csv\n",
      "Trained 8500000 sentences. Now in output_6.csv\n",
      "Trained 8600000 sentences. Now in output_6.csv\n",
      "Trained 8700000 sentences. Now in output_6.csv\n",
      "Trained 8800000 sentences. Now in output_6.csv\n",
      "Trained 8900000 sentences. Now in output_11.csv\n",
      "Trained 9000000 sentences. Now in output_11.csv\n",
      "Trained 9100000 sentences. Now in output_11.csv\n",
      "Trained 9200000 sentences. Now in output_11.csv\n",
      "Trained 9300000 sentences. Now in output_11.csv\n",
      "Trained 9400000 sentences. Now in output_11.csv\n",
      "Trained 9500000 sentences. Now in output_11.csv\n",
      "Trained 9600000 sentences. Now in output_11.csv\n",
      "Trained 9700000 sentences. Now in output_11.csv\n",
      "Trained 9800000 sentences. Now in output_11.csv\n",
      "Trained 9900000 sentences. Now in output_11.csv\n",
      "Trained 10000000 sentences. Now in output_11.csv\n",
      "Trained 10100000 sentences. Now in output_11.csv\n",
      "Trained 10200000 sentences. Now in output_11.csv\n",
      "Trained 10300000 sentences. Now in output_11.csv\n",
      "Trained 10400000 sentences. Now in output_11.csv\n",
      "Trained 10500000 sentences. Now in output_11.csv\n",
      "Trained 10600000 sentences. Now in output_11.csv\n",
      "Trained 10700000 sentences. Now in output_11.csv\n",
      "Trained 10800000 sentences. Now in output_11.csv\n",
      "Trained 10900000 sentences. Now in output_11.csv\n",
      "Trained 11000000 sentences. Now in output_11.csv\n",
      "Trained 11100000 sentences. Now in output_11.csv\n",
      "Trained 11200000 sentences. Now in output_11.csv\n",
      "Trained 11300000 sentences. Now in output_11.csv\n",
      "Trained 11400000 sentences. Now in output_11.csv\n",
      "Trained 11500000 sentences. Now in output_11.csv\n",
      "Trained 11600000 sentences. Now in output_11.csv\n",
      "Trained 11700000 sentences. Now in output_11.csv\n",
      "Trained 11800000 sentences. Now in output_11.csv\n",
      "Trained 11900000 sentences. Now in output_11.csv\n",
      "Trained 12000000 sentences. Now in output_11.csv\n",
      "Trained 12100000 sentences. Now in output_11.csv\n",
      "Trained 12200000 sentences. Now in output_11.csv\n",
      "Trained 12300000 sentences. Now in output_11.csv\n",
      "Trained 12400000 sentences. Now in output_11.csv\n",
      "Trained 12500000 sentences. Now in output_11.csv\n",
      "Trained 12600000 sentences. Now in output_11.csv\n",
      "Trained 12700000 sentences. Now in output_11.csv\n",
      "Trained 12800000 sentences. Now in output_11.csv\n",
      "Trained 12900000 sentences. Now in output_11.csv\n",
      "Trained 13000000 sentences. Now in output_11.csv\n",
      "Trained 13100000 sentences. Now in output_11.csv\n",
      "Trained 13200000 sentences. Now in output_11.csv\n",
      "Trained 13300000 sentences. Now in output_16.csv\n",
      "Trained 13400000 sentences. Now in output_16.csv\n",
      "Trained 13500000 sentences. Now in output_16.csv\n",
      "Trained 13600000 sentences. Now in output_16.csv\n",
      "Trained 13700000 sentences. Now in output_16.csv\n",
      "Trained 13800000 sentences. Now in output_16.csv\n",
      "Trained 13900000 sentences. Now in output_16.csv\n",
      "Trained 14000000 sentences. Now in output_16.csv\n",
      "Trained 14100000 sentences. Now in output_16.csv\n"
     ]
    }
   ],
   "source": [
    "    data = []\n",
    "    n_sen=0\n",
    "    is_first = True\n",
    "    for file in files:\n",
    "        source = open(INPUT_PATH + file, encoding='UTF8')\n",
    "        line = source.readline()\n",
    "        sentence = []\n",
    "        while 1:\n",
    "            line = source.readline().strip()\n",
    "            if line == '':\n",
    "                break\n",
    "            line = line.replace(',NA,', ',\"NA\",')\n",
    "            pos = line.find('\",\"')\n",
    "            text = line[pos + 2:]\n",
    "            if text[:3] == '\",\"':\n",
    "                #カンマは無視\n",
    "                continue\n",
    "            text = text[1:-1]\n",
    "            arr = text.split('\",\"')\n",
    "            if arr[0].isdigit():\n",
    "                if len(arr[0])==4:\n",
    "                    arr[0] = \"<YEAR>\"\n",
    "                elif len(arr[0])==3:\n",
    "                    arr[0] = \"<3_DIGIT>\"\n",
    "                elif len(arr[0])==2:\n",
    "                    arr[0] = \"<2_DIGIT>\"\n",
    "            if arr[0] != '<eos>':\n",
    "                sentence.append(arr[0])\n",
    "            else:\n",
    "                data.append(sentence)\n",
    "                if len(data) == 10000:\n",
    "                    if is_first:\n",
    "                        model = word2vec.Word2Vec(data, size=128, window=5, min_count=1, workers=4)\n",
    "                    else:\n",
    "                        model.train(data)\n",
    "                    n_sen += 10000\n",
    "                    if n_sen % 100000 == 0:\n",
    "                        print(\"\\rTrained %i sentences. Now in %s\" % (n_sen, file))\n",
    "                    data=[]\n",
    "                sentence = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
